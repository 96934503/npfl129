### Lecture: 9. Decision Trees, Random Forests
#### Date: Nov 28
#### Slides: https://ufal.mff.cuni.cz/~courses/npfl129/2324/slides/?09
#### Reading: https://ufal.mff.cuni.cz/~courses/npfl129/2324/slides.pdf/npfl129-2324-09.pdf,PDF Slides
#### Lecture assignment: decision_tree
#### Lecture assignment: random_forest
#### Lecture assignment: human_activity_recognition
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl129/2324/npfl129-2324-09-practicals-english.mp4, EN Practicals
#### Questions: #lecture_9_questions

**Learning objectives.** After the lecture you shoud be able to

- Implement Decision Trees and Random Forests for classification and regression

- Explain how the splitting criterion depend on optimized loss function

- Tell how Random Forests differ from Gradient Boosted Decision Trees

**Covered topics** and where to find more:

- Decision trees [Section 14.4 of PRML]
- Random forests
